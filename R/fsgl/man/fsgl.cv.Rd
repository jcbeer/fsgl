% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fsgl.cv.R, R/fsgl.cv.par.R
\name{fsgl.cv}
\alias{fsgl.cv}
\alias{fsgl.cv}
\title{Cross-validation for Fused Sparse Group Lasso}
\usage{
fsgl.cv(X, Y, K, nj, nd, ngroups, groupsizes, alphagamma, lambda, k,
  folds = NULL, beta0 = NULL, theta0 = NULL, mu0 = NULL, rho = 1,
  Niter = 2000, epsilon_abs = 10^-3, epsilon_rel = 10^-3,
  verbose = FALSE)

fsgl.cv(X, Y, K, nj, nd, ngroups, groupsizes, alphagamma, lambda, k,
  folds = NULL, beta0 = NULL, theta0 = NULL, mu0 = NULL, rho = 1,
  Niter = 2000, epsilon_abs = 10^-3, epsilon_rel = 10^-3,
  verbose = FALSE)
}
\arguments{
\item{X}{a n*p matrix of predictor variables with observations in rows.}

\item{Y}{a n*1 vector of the response variable.}

\item{K}{a (nj + nd + ng)*p matrix encoding the lasso penalty (first nj rows), the graph structure for the fused penalty (the next nd rows), and the group structure for the group penalty (last ng rows). Can be made with function \code{makeKmatrix}.}

\item{nj}{number of rows of K that encode the lasso penalty. If lasso penalty is applied to all coefficients then this will equal p.}

\item{nd}{number of rows of K that encode the graph structure for the fused penalty.}

\item{ngroups}{number of groups for the group penalty.}

\item{groupsizes}{a vector of length ngroups that gives the size of each group in the order they appear in the K matrix. Sum should equal ng.}

\item{alphagamma}{a two-column matrix with rows containing alpha, gamma pairs at which cross-validation will be done for a range of lambda values. alpha is a tuning parameter that controls the degree of group (alpha = 0) vs L1 (alpha=1) sparsity. gamma is a tuning parameter that controls the degree of sparsity (gamma=1) vs fusion (gamma=0) penalty. 0 <= alpha, gamma <= 1}

\item{lambda}{vector of decreasing lambda values at which k-fold cross-validation will be done. tuning parameter that controls the overall degree of regularization.}

\item{k}{number of folds for cross-validation.}

\item{folds}{a vector encoding the fold assignments. By default folds will be randomly assigned.}

\item{beta0}{starting values for beta. Defaults to zero vector.}

\item{theta0}{starting values for theta. Defaults to zero vector.}

\item{mu0}{starting values for mu. Defaults to zero vector.}

\item{rho}{step size for ADMM algorithm. Defaults to 1.}

\item{Niter}{number of ADMM iterations used for each fsgl fit. Defaults to 2000.}

\item{epsilon_abs}{absolute tolerance for ADMM convergence. Defaults to 10^-3.}

\item{epsilon_rel}{relative tolerance for ADMM convergence. Defaults to 10^-3.}

\item{verbose}{if TRUE will print progress through alpha, gamma combinations for each fold. Defaults to FALSE.}

\item{X}{a n*p matrix of predictor variables with observations in rows.}

\item{Y}{a n*1 vector of the response variable.}

\item{K}{a (nj + nd + ng)*p matrix encoding the lasso penalty (first nj rows), the graph structure for the fused penalty (the next nd rows), and the group structure for the group penalty (last ng rows). Can be made with function \code{makeKmatrix}.}

\item{nj}{number of rows of K that encode the lasso penalty. If lasso penalty is applied to all coefficients then this will equal p.}

\item{nd}{number of rows of K that encode the graph structure for the fused penalty.}

\item{ngroups}{number of groups for the group penalty.}

\item{groupsizes}{a vector of length ngroups that gives the size of each group in the order they appear in the K matrix. Sum should equal ng.}

\item{alphagamma}{a two-column matrix with rows containing alpha, gamma pairs at which cross-validation will be done for a range of lambda values. alpha is a tuning parameter that controls the degree of group (alpha = 0) vs L1 (alpha=1) sparsity. gamma is a tuning parameter that controls the degree of sparsity (gamma=1) vs fusion (gamma=0) penalty. 0 <= alpha, gamma <= 1}

\item{lambda}{vector of decreasing lambda values at which k-fold cross-validation will be done. tuning parameter that controls the overall degree of regularization.}

\item{k}{number of folds for cross-validation.}

\item{folds}{a vector encoding the fold assignments. By default folds will be randomly assigned.}

\item{beta0}{starting values for beta. Defaults to zero vector.}

\item{theta0}{starting values for theta. Defaults to zero vector.}

\item{mu0}{starting values for mu. Defaults to zero vector.}

\item{rho}{step size for ADMM algorithm. Defaults to 1.}

\item{Niter}{number of ADMM iterations used for each fsgl fit. Defaults to 2000.}

\item{epsilon_abs}{absolute tolerance for ADMM convergence. Defaults to 10^-3.}

\item{epsilon_rel}{relative tolerance for ADMM convergence. Defaults to 10^-3.}

\item{verbose}{if TRUE will print progress through alpha, gamma combinations for each fold. Defaults to FALSE.}
}
\description{
Does k-fold validation for \code{fsgl.fit}.

Does k-fold validation for \code{fsgl.fit}.
}
\examples{
Kmatrix <- makeKmatrix2d(dim1=3, dim2=3, groups=c(1, 2, 3, 2, 2, 1, 3, 3, 1))
x <- matrix(rnorm(54), nrow=6)
y <- x \%*\% c(0, 0, 10, 0, 0, 0, 10, 10, 0)
# define lambda
Lambda <- 10 ^ seq(3, -3, length = 50)
# define alpha and gamma 
alphas <- c(rep(0,5), rep(0.2, 4), rep(0.5, 4), rep(0.8, 4), rep(1, 4))
gammas <- c(0, rep(c(0.2, 0.5, 0.8, 1), 5))
AlphaGamma <- cbind(alphas, gammas)
cv <- fsgl.cv(X=x, Y=y, K=Kmatrix$K, nj=Kmatrix$nj, nd=Kmatrix$nd, ngroups=Kmatrix$ngroups, groupsizes=Kmatrix$groupsizes, alphagamma=AlphaGamma, lambda=Lambda, k=3, verbose=TRUE)
Kmatrix <- makeKmatrix2d(dim1=3, dim2=3, groups=c(1, 2, 3, 2, 2, 1, 3, 3, 1))
x <- matrix(rnorm(54), nrow=6)
y <- x \%*\% c(0, 0, 10, 0, 0, 0, 10, 10, 0)
# define lambda
Lambda <- 10 ^ seq(3, -3, length = 50)
# define alpha and gamma 
alphas <- c(rep(0,5), rep(0.2, 4), rep(0.5, 4), rep(0.8, 4), rep(1, 4))
gammas <- c(0, rep(c(0.2, 0.5, 0.8, 1), 5))
AlphaGamma <- cbind(alphas, gammas)
cv <- fsgl.cv(X=x, Y=y, K=Kmatrix$K, nj=Kmatrix$nj, nd=Kmatrix$nd, ngroups=Kmatrix$ngroups, groupsizes=Kmatrix$groupsizes, alphagamma=AlphaGamma, lambda=Lambda, k=3, verbose=TRUE)
}
\keyword{lasso}
